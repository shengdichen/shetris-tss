rl-algs
@misc{PPO,
    doi = {10.48550/ARXIV.1707.06347},
    url = {https://arxiv.org/abs/1707.06347},
    author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and
        Radford, Alec and Klimov, Oleg},
    keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences,
        FOS: Computer and information sciences},
    title = {Proximal Policy Optimization Algorithms},
    publisher = {arXiv},
    year = {2017},
    copyright = {arXiv.org perpetual, non-exclusive license},
}


rl-theory
@misc{RL-tutorial-overview,
    doi = {10.48550/ARXIV.2005.01643},
    url = {https://arxiv.org/abs/2005.01643},
    author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu,
        Justin},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Machine Learning (stat.ML), FOS: Computer and information sciences, FOS:
            Computer and information sciences},
    title = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives
        on Open Problems},
    publisher = {arXiv},
    year = {2020},
    copyright = {arXiv.org perpetual, non-exclusive license},
}

@misc{what-matters-in-rl,
    doi = {10.48550/ARXIV.2006.05990},
    url = {https://arxiv.org/abs/2006.05990},
    author = {Andrychowicz, Marcin and Raichuk, Anton and Stańczyk, Piotr and
        Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot,
        Léonard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin
            and Gelly, Sylvain and Bachem, Olivier},
    keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS:
        Computer and information sciences, FOS: Computer and information
            sciences},
    title = {What Matters In On-Policy Reinforcement Learning? A Large-Scale
        Empirical Study},
    publisher = {arXiv},
    year = {2020},
    copyright = {arXiv.org perpetual, non-exclusive license},

}

@misc{challenges-in-rl,
    doi = {10.48550/ARXIV.1904.12901},
    url = {https://arxiv.org/abs/1904.12901},
    author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and
            information sciences, FOS: Computer and information sciences},
    title = {Challenges of Real-World Reinforcement Learning},
    publisher = {arXiv},
    year = {2019},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{why-rl-difficult,
    doi = {10.48550/ARXIV.2107.06277},
    url = {https://arxiv.org/abs/2107.06277},
    author = {Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and
        Adams, Ryan P. and Levine, Sergey},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Machine Learning (stat.ML), FOS: Computer and information sciences, FOS:
            Computer and information sciences},
    title = {Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit
        Partial Observability},
    publisher = {arXiv},
    year = {2021},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{reward-enginnering,
    author = {
        Dewey, Dan
    },
    year = {2014},
    title = {
        Reinforcement Learning and the Reward Engineering Principle
    },
    booktitle = {
        AAAI Spring Symposia
    },
}
