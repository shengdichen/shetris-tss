rl-algs
@article{TD-gammon,
    title={Temporal Difference Learning and TD-Gammon},
    author={Gerald Tesauro},
    journal={J. Int. Comput. Games Assoc.},
    year={1995},
    volume={18},
    pages={88}
}

@mic{Q-learning-original,
    doi = {10.1007/BF00992698},
    url = {https://doi.org/10.1007/BF00992698},
    author = {
        Watkins, Christopher J. C. H. and Dayan, Peter
    },
    keywords = {Machine Learning (cs.LG), FOS: Computer and information
        sciences, FOS: Computer and information sciences},
    title = {Q-learning},
    publisher = {Machine Learning},
    year = {1992},
    volume={8},
    pages={279-292},
}

@misc{DQN-original,
    doi = {10.48550/ARXIV.1312.5602},
    url = {https://arxiv.org/abs/1312.5602},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and
        Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller,
        Martin},
    keywords = {Machine Learning (cs.LG), FOS: Computer and information
        sciences, FOS: Computer and information sciences},
    title = {Playing Atari with Deep Reinforcement Learning},
    publisher = {arXiv},
    year = {2013},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{DQN-deepmind-implementation,
    author = {
        Google Deepmind
    },
    year = {2015},
    title = {
        Lua/Torch implementation of DQN
    },
    publisher = {GitHub},
    journal = {
        GitHub repository
    },
    howpublished = {
        \url{https://github.com/deepmind/dqn}
    },
}

@misc{DQN-deepmind-tweaked,
    author = {
        Ilya Kuzovkin
    },
    year = {2018},
    title = {
        Tweaked Lua/Torch implementation of DQN
    },
    publisher = {GitHub},
    journal = {
        GitHub repository
    },
    howpublished = {
        \url{https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner}
    },
}

@article{dqn-nature,
    title={Human-level control through deep reinforcement learning},
    author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A.
        Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin
            A. Riedmiller and Andreas Fidjeland and Georg Ostrovski and Stig
            Petersen and Charlie Beattie and Amir Sadik and Ioannis Antonoglou
            and Helen King and Dharshan Kumaran and Daan Wierstra and Shane
            Legg and Demis Hassabis},
    journal={Nature},
    year={2015},
    volume={518},
    pages={529-533}
}

@misc{PPO,
    doi = {10.48550/ARXIV.1707.06347},
    url = {https://arxiv.org/abs/1707.06347},
    author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and
        Radford, Alec and Klimov, Oleg},
    keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences,
        FOS: Computer and information sciences},
    title = {Proximal Policy Optimization Algorithms},
    publisher = {arXiv},
    year = {2017},
    copyright = {arXiv.org perpetual, non-exclusive license},
}

@article{A2C,
    doi = {10.48550/ARXIV.1602.01783},
    url = {https://arxiv.org/abs/1602.01783},
    author = {
        Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and
            Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver,
        David and Kavukcuoglu, Koray
    },
    keywords = {
        Machine Learning (cs.LG), FOS: Computer and information sciences, FOS:
            Computer and information sciences
    },
    title = {
        Asynchronous Methods for Deep Reinforcement Learning
    },
    publisher = {arXiv},
    year = {2016},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

rl-theory
@misc{RL-tutorial-overview,
    doi = {10.48550/ARXIV.2005.01643},
    url = {https://arxiv.org/abs/2005.01643},
    author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu,
        Justin},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Machine Learning (stat.ML), FOS: Computer and information sciences, FOS:
            Computer and information sciences},
    title = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives
        on Open Problems},
    publisher = {arXiv},
    year = {2020},
    copyright = {arXiv.org perpetual, non-exclusive license},
}

@misc{what-matters-in-rl,
    doi = {10.48550/ARXIV.2006.05990},
    url = {https://arxiv.org/abs/2006.05990},
    author = {Andrychowicz, Marcin and Raichuk, Anton and Stańczyk, Piotr and
        Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot,
        Léonard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin
            and Gelly, Sylvain and Bachem, Olivier},
    keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS:
        Computer and information sciences, FOS: Computer and information
            sciences},
    title = {What Matters In On-Policy Reinforcement Learning? A Large-Scale
        Empirical Study},
    publisher = {arXiv},
    year = {2020},
    copyright = {arXiv.org perpetual, non-exclusive license},

}

@misc{challenges-in-rl,
    doi = {10.48550/ARXIV.1904.12901},
    url = {https://arxiv.org/abs/1904.12901},
    author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and
            information sciences, FOS: Computer and information sciences},
    title = {Challenges of Real-World Reinforcement Learning},
    publisher = {arXiv},
    year = {2019},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{why-rl-difficult,
    doi = {10.48550/ARXIV.2107.06277},
    url = {https://arxiv.org/abs/2107.06277},
    author = {Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and
        Adams, Ryan P. and Levine, Sergey},
    keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI),
        Machine Learning (stat.ML), FOS: Computer and information sciences, FOS:
            Computer and information sciences},
    title = {Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit
        Partial Observability},
    publisher = {arXiv},
    year = {2021},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{reward-enginnering,
    author = {
        Dewey, Dan
    },
    year = {2014},
    title = {
        Reinforcement Learning and the Reward Engineering Principle
    },
    booktitle = {
        AAAI Spring Symposia
    },
}


classic-control
@book{bertsekas_1995,
    author = {
        Bertsekas, D. P.
    },
    year = {1995},
    title = {
        Dynamic programming and optimal control
    },
}

@book{bellman_1957,
    author = {
        Bellman, Richard
    },
    title = {
        Dynamic Programming
    },
    publisher = {
        Princeton University Press
    },
    year = {1957},
    address = {Princeton, NJ, USA},
    edition = {1},
}
