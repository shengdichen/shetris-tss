#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsart
\use_default_options true
\master ../main.lyx
\begin_removed_modules
theorems-ams
\end_removed_modules
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
theorems-ams-chap-bytype
theorems-ams-extended-chap-bytype
algorithm2e
customHeadersFooters
enumitem
logicalmkup
todonotes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Libertinus Serif"
\font_sans "default" "Avenir LT Std"
\font_typewriter "default" "Source Code Pro"
\font_math "auto" "default"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 93
\use_microtype true
\use_dash_ligatures true
\graphics default
\default_output_format pdf5
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=black,  frenchlinks=true, citecolor=black, urlcolor=blue, filecolor=blue, pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine biblatex
\cite_engine_type numerical
\biblio_options entryhead=true, entrykey=false
\biblatex_bibstyle reading
\biblatex_citestyle alphabetic-verb
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 0.75in
\topmargin 0.75in
\rightmargin 0.75in
\bottommargin 1in
\headsep 0.3in
\footskip 0.3in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side right
\quotes_style danish
\dynamic_quotes 1
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\listings_params "basicstyle={\ttfamily\normalsize},commentstyle={\sffamily},columns=fullflexible,numbers=left,numberstyle={\ttfamily\scriptsize},stepnumber=1,numberblanklines=false,firstline=1,numbersep=9pt,frame=tlb,framexleftmargin=3pt,framextopmargin=2pt,framexbottommargin=1pt,aboveskip={\medskipamount},belowskip={\medskipamount},captionpos=b,floatplacement=tbp,tabsize=4,resetmargins=false,breaklines=true,breakatwhitespace=false,breakautoindent=true,breakindent=0pt,prebreak={...},postbreak={...},extendedchars=true"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Synopsis
\end_layout

\begin_layout Standard
This thesis-project explores the possibility of the deployment of methods
 of Reinforcement-Learning (RL) to the game-play of Tetris.
 An amalgamation of the name of its author and the underlying game to solve
 leads to its internal code-name of 
\begin_inset Quotes xld
\end_inset

Shetris
\begin_inset Quotes xrd
\end_inset

, as shown in the header section.
\end_layout

\begin_layout Standard
The purpose of applying techniques from RL to the specific game-play of
 Tetris tangents upon two very specific domains, both boasting of a broad
 range of established researches.
 Notable examples are enumerated below.
\end_layout

\begin_layout Subsection
Related Researches
\end_layout

\begin_layout Subsubsection
On the game of Tetris
\end_layout

\begin_layout Standard
Analysis of the game-play and rule-sets performed solely on the Tetris game
 are generally published by experts of the game, such as the individually
 maintained 
\begin_inset CommandInset citation
LatexCommand cite
key "koryan"
literal "false"

\end_inset

, as well as the community wiki 
\begin_inset CommandInset citation
LatexCommand cite
key "tetris-wiki"
literal "false"

\end_inset

, whose relevance is further discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Source-of-Information"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
Purely theoretical researches such as 
\begin_inset CommandInset citation
LatexCommand cite
key "demaine-n-mino,demaine-np"
literal "false"

\end_inset

 have demonstrated the 
\begin_inset Formula $NP$
\end_inset

-completeness of optimally solving 
\begin_inset Quotes xld
\end_inset

the Tetris-problem
\begin_inset Quotes xrd
\end_inset

.
\end_layout

\begin_layout Standard
On the other hand, algorithms from the field of RL have been observed to
 perform reasonably well in learning the strategy for playing Tetris, as
 demonstrated in 
\begin_inset CommandInset citation
LatexCommand cite
key "hk,reduced-tetris,stanford,tetris-best-ai,tetris-nuno,tetris-rl-survey,uvipen"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Reinforcement-Learning has been shown to achieve human level-performance
 in classical gaming environments
\begin_inset Note Note
status open

\begin_layout Plain Layout
Nature paper
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Concerning this thesis, recent algorithmic breakthroughs for DQN, PPO
\begin_inset CommandInset citation
LatexCommand cite
key "PPO"
literal "false"

\end_inset

 and
\end_layout

\begin_layout Subsubsection
On Reinforcement-Learning RL
\end_layout

\begin_layout Standard
Reinforcement-Learning finds root in established literature from classical
 control-theory, with reference-literature 
\begin_inset CommandInset citation
LatexCommand cite
key "bertsekas_1995,bellman_1957"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The original idea of Q-Learning in 
\begin_inset CommandInset citation
LatexCommand cite
key "Q-learning-original"
literal "false"

\end_inset

 has recently been augmented with techniques of deep-learning, giving rise
 to the method of Deep Q-Networks (DQN) as originally published in 
\begin_inset CommandInset citation
LatexCommand cite
key "DQN-original"
literal "false"

\end_inset

.
 The landmark publication 
\begin_inset CommandInset citation
LatexCommand cite
key "dqn-nature"
literal "false"

\end_inset

 shows the potency of this fusion on the collection of Atari-games, achieving
 super-human performance on multiple occasions.
\end_layout

\begin_layout Standard
The DQN has been notably implemented by the original publisher 
\begin_inset CommandInset citation
LatexCommand cite
key "DQN-deepmind-implementation"
literal "false"

\end_inset

 and further tuned by 
\begin_inset CommandInset citation
LatexCommand cite
key "DQN-deepmind-tweaked"
literal "false"

\end_inset

 and utilized by projects such as 
\begin_inset CommandInset citation
LatexCommand cite
key "DQN-deepmind-tweaked,uvipen,tetris-nuno"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
General libraries such as 
\begin_inset CommandInset citation
LatexCommand cite
key "sb3"
literal "false"

\end_inset

 provide reference implementations of exemplary methods of RL beyond DQN,
 such as those proposed in the researches of 
\begin_inset CommandInset citation
LatexCommand cite
key "PPO,A2C"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Current Deficiencies
\end_layout

\begin_layout Plain Layout
Justifications of Decisions
\end_layout

\begin_layout Plain Layout
The cursory mentioning above of the implementation of a separate Tetris-game
 is 
\begin_inset Flex Emph
status open

\begin_layout Plain Layout
de facto
\end_layout

\end_inset

 the result of much analysis.
\end_layout

\begin_layout Subsection
The unpleasantness
\end_layout

\begin_layout Plain Layout
But they all suffer from one or more critical drawbacks:
\end_layout

\begin_layout Enumerate
One is made with raw NES, raw field: very long training: at the beginning,
 random jittering all the time
\end_layout

\begin_layout Enumerate
raw movement 
\begin_inset Note Note
status open

\begin_layout Plain Layout
paper in HK: does this count?
\end_layout

\end_inset

, namely the GitHub repo (very easy to get started)
\end_layout

\begin_layout Enumerate
raw data-source (scanning the whole field)
\begin_inset Note Note
status open

\begin_layout Plain Layout
do we have a paper?
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
But probably the biggest drawback of using existing tetris implementations
 is the lack of:
\end_layout

\begin_layout Enumerate
training
\end_layout

\begin_layout Enumerate
testing
\end_layout

\begin_layout Enumerate
viewing
\end_layout

\begin_layout Plain Layout
possibilities.
 It is thus necessary to implement our own Tetris game for truly granular
 control.
\end_layout

\begin_layout Enumerate
Few existing solutions of Tetris with Reinforcement-Learning follow a standardiz
ed frame-work for describing the game.
 Indeed, though both 
\begin_inset CommandInset citation
LatexCommand cite
key "uvipen,tetris-nuno"
literal "false"

\end_inset

 achieve respectable results for agent-training, the environment itself
 is designed as the heart wishes by the author.
\end_layout

\begin_layout Enumerate
Insufficient modularity: the game-logic and the environment's observation
 or action should be isolated : this allows modification of the training
 process by varying observation, action and reward, which can be thought
 of as the tuning of hyper-parameters on a more untraditional, more elevated
 level than that of the learning-algorithm.
\end_layout

\begin_layout Enumerate
Non-extendability and modifiability of the engine itself: the generator,
 for example, as seen in later chapters, critically influences the entire
 train-test pipeline.
 Building upon the previous argument, components within the game-logic must
 themselves also be segregated into separate modules.
\end_layout

\begin_layout Enumerate
The few 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
gym
\end_layout

\end_inset

 compliant environments leave much to be desired as well.
 Apart from the same argument of inadequate management of source code, examples
 such as 
\begin_inset Note Note
status open

\begin_layout Plain Layout
the NES environment: put in the link
\end_layout

\end_inset

 directly use the ROM of the game on the NES platform.
 While this would make for spectacular results, the difficulty of extracting
 information from the said ROM is almost insurmountable
\begin_inset Note Note
status open

\begin_layout Plain Layout
ROM-hack website for NES
\end_layout

\end_inset

: it seems almost impossible to extract the amount of required data for
 conducting training under real-life resource bounds.
 The failure to successfully train models on raw data with minimal ROM-hacking
 is well documented in 
\begin_inset Note Note
status open

\begin_layout Plain Layout
HK paper
\end_layout

\end_inset

.
\end_layout

\begin_layout Plain Layout
The enumeration above is not exhaustive: some are based purely on tried
 and true principles from traditional software engineering; others on real-life
 constraints on resource and time of computing.
\end_layout

\begin_layout Plain Layout
The immediate
\begin_inset Foot
status open

\begin_layout Plain Layout
In fact, the actual time taken for this decision is far from being 
\begin_inset Quotes xld
\end_inset

immediate
\begin_inset Quotes xrd
\end_inset

.
 See Chapter V for details.
\end_layout

\end_inset

 realization was the necessity to implement the project from
\end_layout

\end_inset


\end_layout

\begin_layout Section
Technicalities
\end_layout

\begin_layout Standard
A summary of the technical details of this thesis is presented as follows.
\end_layout

\begin_layout Subsection
Programming
\end_layout

\begin_layout Standard
The main source-code package is further decomposed into two separate sub-package
s: the first implements the logic of the Tetris-game, and the second performs
 analysis, training and testing.
\end_layout

\begin_layout Subsubsection
General usages
\end_layout

\begin_layout Standard
The programming is performed with the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
Python
\end_layout

\end_inset

 language.
 Despite the dynamic-typing nature of the language, the source-code utilizes
 extensive type-hinting.
 Python versions no earlier than 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
Python 3.9
\end_layout

\end_inset

 is required
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Version requirement of 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
Python
\end_layout

\end_inset

's 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
typing
\end_layout

\end_inset

-Module: 
\begin_inset CommandInset href
LatexCommand href
target "https://docs.python.org/3/library/typing.html#module-contents"
literal "false"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
The source-code is consistently processed by the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
black
\end_layout

\end_inset

-formatter 
\begin_inset CommandInset citation
LatexCommand cite
key "black"
literal "false"

\end_inset

 and thus implicitly conforms to the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
PEP8
\end_layout

\end_inset

 standard.
\end_layout

\begin_layout Subsubsection
Required packages
\end_layout

\begin_layout Standard
The framework for the agent-interactive environment is provided by the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
gym
\end_layout

\end_inset

-package developed by OpenAI
\begin_inset CommandInset citation
LatexCommand cite
key "gym"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The reference implementation of algorithms of RL, for example, the Deep-Q-Networ
k (DQN) 
\begin_inset CommandInset citation
LatexCommand cite
key "dqn-nature,DQN-original"
literal "false"

\end_inset

 and the Proximal-Policy-Optimization (PPO) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "PPO"
literal "false"

\end_inset

, are provided by stable-baselines3
\begin_inset CommandInset citation
LatexCommand cite
key "sb3"
literal "false"

\end_inset

, referred to as 
\begin_inset Quotes xld
\end_inset


\begin_inset Flex Code
status open

\begin_layout Plain Layout
SB3
\end_layout

\end_inset


\begin_inset Quotes xrd
\end_inset

 in this thesis.
\end_layout

\begin_layout Standard
Note that both 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
gym
\end_layout

\end_inset

 and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
SB3
\end_layout

\end_inset

 enforce project-wide type-hinting as well.
\end_layout

\begin_layout Subsection
Formatting and Typesetting
\end_layout

\begin_layout Standard
This paper is compiled by the Lua\SpecialChar TeX
 typesetting-engine featuring the open-source
 font-packages of 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
Libertinus
\end_layout

\end_inset

 and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
Source-Code-Pro
\end_layout

\end_inset

.
\end_layout

\begin_layout Subsection
Tracking
\end_layout

\begin_layout Standard
The source-code of the 
\begin_inset Flex Noun
status open

\begin_layout Plain Layout
Shetris
\end_layout

\end_inset

-Project is distributed under the following repositories:
\end_layout

\begin_layout Itemize
The modules for the formulation of various agents, as well as those for
 training and testing are published under the repository: 
\begin_inset CommandInset href
LatexCommand href
name "Link to GitHub"
target "https://github.com/shengdichen/shetris-train"
literal "false"

\end_inset

;
\end_layout

\begin_layout Itemize
All other aspects of the game, including the 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
engine
\end_layout

\end_inset

 as described Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Essential-Implementations"
plural "false"
caps "false"
noprefix "false"

\end_inset

, are found at: 
\begin_inset CommandInset href
LatexCommand href
name "Link to GitHub"
target "https://github.com/shengdichen/shetris-game"
literal "false"

\end_inset

;
\end_layout

\begin_layout Itemize
This thesis-document itself if accessible under: 
\begin_inset CommandInset href
LatexCommand href
name "Link to GitHub"
target "https://github.com/shengdichen/shetris-tss"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Both source-code repositories deploy the 
\begin_inset Quotes xld
\end_inset

GNU Affero General Public License v3.0
\begin_inset Quotes xrd
\end_inset

 license, else known as 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
GNU AGPLv3
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Subsubsection
Tracking and Control
\end_layout

\begin_layout Plain Layout
This particular thesis documents the conception, the implementation and
 the results achieved in The entire project consists of two fundamental
 parts: t
\end_layout

\begin_layout Plain Layout
The Shetris-Project is under extensive version control by 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
git
\end_layout

\end_inset

: three lower-level repositories are created: the first documents the 
\begin_inset Quotes xld
\end_inset

engine
\begin_inset Quotes xrd
\end_inset

 
\end_layout

\begin_layout Plain Layout
This thesis documents the results obtained until version 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
V?
\end_layout

\end_inset

, marked with the signed 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
git-tag
\end_layout

\end_inset

 of 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
#tag-number
\end_layout

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_body
\end_document
